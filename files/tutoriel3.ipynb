{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Optimization for Deep learning**\n",
    "\n",
    "**Author** : Ryan BOUSTANY\n",
    "\n",
    "**Session 3:**\n",
    "- Train a LeNet5 network with MNIST datatset\n",
    "\n",
    "This tutorial aims to provide a comprehensive understanding of Convolutional Neural Networks (CNNs), primarily focusing on the implementation of LeNet-5 using the MNIST dataset. \n",
    "\n",
    "\n",
    "Convolutional Neural Networks (CNNs) are a class of deep neural networks highly effective in tasks related to image recognition, image classification, and similar types of problems. LeNet-5, proposed by Yann LeCun in 1998, is one of the pioneering models in this domain. This tutorial will walk you through the process of implementing LeNet-5 using PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing Required Libraries\n",
    "\n",
    "Let's start by importing the libraries we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Preparation\n",
    "\n",
    "The MNIST dataset is commonly used for handwritten digit classification and consists of 60,000 training images and 10,000 testing images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transform operation to normalize the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Download and load the MNIST dataset for training and testing\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Understanding LeNet-5 Architecture\n",
    "LeNet-5 consists of the following layers:\n",
    "\n",
    "- Convolutional Layer 1: 6 output channels, 5x5 kernel\n",
    "- Activation: Tanh\n",
    "- Average Pooling\n",
    "- Convolutional Layer 2: 16 output channels, 5x5 kernel\n",
    "- Activation: Tanh\n",
    "- Average Pooling\n",
    "- Fully Connected Layer 1: 120 units\n",
    "- Fully Connected Layer 2: 84 units\n",
    "- Fully Connected Layer 3 (Output Layer): 10 units\n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/ryanboustany/ryanboustany.github.io/master/files/lenet5.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        # Define the convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        \n",
    "        # Define the fully connected layers\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # TODO: Implement the forward pass\n",
    "        # Your code here\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Training\n",
    "\n",
    "Loss Function and Optimizer : we will use Cross-Entropy Loss and the SGD optimizer for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss, and optimizer\n",
    "model = LeNet5()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# TODO: Implement the training loop\n",
    "# Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Model Evaluation\n",
    "\n",
    "After training, we evaluate the model's performance on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the model on the 10000 test images: {100 * correct / total}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Training Function with Different Optimizers\n",
    "\n",
    "See to see optimizers algorithms : https://pytorch.org/docs/stable/optim.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lenet5_with_optimizers(optimizers_dict, num_epochs=10):\n",
    "    loss_history = {}\n",
    "    \n",
    "    for opt_name, opt in optimizers_dict.items():\n",
    "        print(f\"Training with {opt_name}...\")\n",
    "        model = LeNet5()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = opt(model.parameters(), lr=0.001)\n",
    "        \n",
    "        loss_history[opt_name] = []\n",
    "        \n",
    "        for epoch in tqdm(range(num_epochs), desc=f\"Epochs ({opt_name})\"):\n",
    "            epoch_loss = 0.0\n",
    "            for i, data in enumerate(trainloader):\n",
    "                inputs, labels = data\n",
    "                # TODO: Zero the gradients of the optimizer\n",
    "                # Your code here\n",
    "                \n",
    "                # TODO: Forward pass\n",
    "                outputs = # Your code here\n",
    "                \n",
    "                # TODO: Compute the loss\n",
    "                loss = # Your code here\n",
    "                \n",
    "                # TODO: Backward pass and optimization step\n",
    "                # Your code here\n",
    "                \n",
    "                epoch_loss += loss.item()\n",
    "            loss_history[opt_name].append(epoch_loss / len(trainloader))\n",
    "    \n",
    "    # Plotting the loss curves\n",
    "    for opt_name, losses in loss_history.items():\n",
    "        plt.plot(range(1, num_epochs + 1), losses, label=f\"{opt_name}\")\n",
    "        \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Optimizer Comparison: Training Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Define the optimizers to be compared\n",
    "optimizers_dict = {\n",
    "    'Adam': optim.Adam,\n",
    "    'SGD': optim.SGD,\n",
    "    'RMSprop': optim.RMSprop\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and compare\n",
    "train_lenet5_with_optimizers(optimizers_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the observed training loss curves, is there an optimizer that exhibits faster convergence than Stochastic Gradient Descent (SGD)? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
