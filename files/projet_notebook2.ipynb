{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST classification using PyTorch\n",
    "\n",
    "In this notebook we will try to classify the Fashion MNIST dataset\n",
    "(https://github.com/zalandoresearch/fashion-mnist) using VGG-like architectures (https://arxiv.org/abs/1409.1556). This notebook is inspired from the MNIST example from PyTorch (https://github.com/pytorch/examples/tree/master/mnist), and introduce tricks to automatically tune and schedule the learning rate for SGD (see this course's slides, https://arxiv.org/abs/1506.01186, and FastAI course for example http://fastai.org).\n",
    "\n",
    "## Fashion MNIST\n",
    "\n",
    "This 10 class dataset is a drop-in replacement for MNIST with clothes instead of digits. MNI is arguably overused in the ML community nowadays. It is subtancially harder to classify.\n",
    "\n",
    "![fashion_mnist](fashion-mnist-sprite.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import a few functions first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from matplotlib.cm import get_cmap\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some system/model hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = False\n",
    "batch_size = 128\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "english_labels = [\"T-shirt/top\",\n",
    "                  \"Trouser\",\n",
    "                  \"Pullover\",\n",
    "                  \"Dress\",\n",
    "                  \"Coat\",\n",
    "                  \"Sandal\",\n",
    "                  \"Shirt\",\n",
    "                  \"Sneaker\",\n",
    "                  \"Bag\",\n",
    "                  \"Ankle boot\"]\n",
    "\n",
    "train_data = datasets.FashionMNIST('data', train=True, download=True,\n",
    "                                   transform=transforms.Compose([\n",
    "                                       transforms.ToTensor(),\n",
    "                                   ]))\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets's compute the average mean and std of the train images. We will\n",
    "use them for normalizing data later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_seen = 0.\n",
    "mean = 0\n",
    "std = 0\n",
    "for train_batch, train_target in train_loader:\n",
    "    batch_size = train_batch.shape[0]\n",
    "    train_batch = train_batch.view(batch_size, -1)\n",
    "    this_mean = torch.mean(train_batch, dim=1)\n",
    "    this_std = torch.sqrt(\n",
    "        torch.mean((train_batch - this_mean[:, None]) ** 2, dim=1))\n",
    "    mean += torch.sum(this_mean, dim=0)\n",
    "    std += torch.sum(this_std, dim=0)\n",
    "    n_samples_seen += batch_size\n",
    "\n",
    "mean /= n_samples_seen\n",
    "std /= n_samples_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2860) tensor(0.3202)\n"
     ]
    }
   ],
   "source": [
    "print(mean, std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now reload the data with a further `Normalize` transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.FashionMNIST('data', train=True, download=False,\n",
    "                                   transform=transforms.Compose([\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(mean=mean.view(1),\n",
    "                                                            std=std.view(1))]))\n",
    "\n",
    "test_data = datasets.FashionMNIST('data', train=False, download=True,\n",
    "                                  transform=transforms.Compose([\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean=mean.view(1),\n",
    "                                                           std=std.view(1))]))\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=32,\n",
    "                                          shuffle=False, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a very simple model, suitable for CPU training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=(3, 3), padding=1)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=(3, 3), padding=1)\n",
    "        self.dropout_2d = nn.Dropout2d(p=0.25)\n",
    "        self.fc1 = nn.Linear(7 * 7 * 20, 128)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout_2d(F.max_pool2d(self.conv1(x), kernel_size=2))\n",
    "        x = self.dropout_2d(F.max_pool2d(self.conv2(x), kernel_size=2))\n",
    "        x = x.view(-1, 7 * 7 * 20)  # flatten / reshape\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.conv1.reset_parameters()\n",
    "        self.conv2.reset_parameters()\n",
    "        self.fc1.reset_parameters()\n",
    "        self.fc2.reset_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercices\n",
    "\n",
    "- Define a VGG-like model: add more convolutional and max pooling layers to increase the number of channels progressively while decreasing the dimensions of the feature maps with max pooling.\n",
    "- Try to use Adam instead of SGD in conjunction with the `find_lr` heuristic and the cosine learning rate schedule below;\n",
    "- (optional) Try data augmentation (horizontal flips, random crops, cutout...);\n",
    "- (optional) Implement the [mixup stochastic label interpolation](https://arxiv.org/abs/1710.09412);\n",
    "- (optional) Try to use batch-normalization;\n",
    "- (optional) Implement skip-connections.\n",
    "\n",
    "See how you compare to other approaches:\n",
    "- https://github.com/zalandoresearch/fashion-mnist\n",
    "- https://www.kaggle.com/zalando-research/fashionmnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/vgg.py\n",
    "class VGGCell(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, depth, max_pooling=True):\n",
    "        super(VGGCell, self).__init__()\n",
    "        self.convs = nn.ModuleList()\n",
    "        for i in range(depth):\n",
    "            if i == 0:\n",
    "                self.convs.append(nn.Conv2d(in_channel, out_channel,\n",
    "                                            kernel_size=(3, 3),\n",
    "                                            padding=1))\n",
    "            else:\n",
    "                self.convs.append(nn.Conv2d(out_channel, out_channel,\n",
    "                                            kernel_size=(3, 3),\n",
    "                                            padding=1))\n",
    "        self.max_pooling = max_pooling\n",
    "\n",
    "    def forward(self, x):\n",
    "        for conv in self.convs:\n",
    "            x = conv(x)\n",
    "        if self.max_pooling:\n",
    "            x = F.max_pool2d(x, kernel_size=(2, 2))\n",
    "        return x\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        vgg1 = VGGCell(1, 32, 2, max_pooling=True)\n",
    "        vgg2 = VGGCell(32, 64, 3, max_pooling=False)\n",
    "        vgg3 = VGGCell(64, 128, 3, max_pooling=True)\n",
    "        vgg4 = VGGCell(128, 256, 3, max_pooling=False)\n",
    "        self.vggs = nn.ModuleList([vgg1, vgg2, vgg3, vgg4])\n",
    "        self.dropout_2d = nn.Dropout2d(p=0.25)\n",
    "        self.fc1 = nn.Linear(7 * 7 * 256, 256)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for vgg in self.vggs:\n",
    "            x = self.dropout_2d(vgg(x))\n",
    "        x = x.view(-1, 7 * 7 * 256)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for vgg in self.vggs:\n",
    "            vgg.reset_parameters()\n",
    "        self.fc1.reset_parameters()\n",
    "        self.fc2.reset_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our model on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=tensor([0.2860]), std=tensor([0.3202]))\n",
       "           )"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "img, target = train_data[0]\n",
    "# n_channel, width, height\n",
    "print(img.shape)\n",
    "\n",
    "# First dimension should contain batch_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot a training image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5t/vn7jb6rx2874dqk3khxl4j540000gn/T/ipykernel_57917/599630494.py:2: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  ax.imshow(img[0].numpy(), cmap=get_cmap('gray'))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.imshow(img[0].numpy(), cmap=get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first dimension of the input data should contain the batch size (due to `torch.nn` API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 Ankle boot\n",
      "tensor([[-2.6250, -2.2063, -1.8975, -2.7263, -2.4924, -1.6666, -2.4997, -2.9292,\n",
      "         -2.5911, -2.1206]], grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "pred = model(img[None, :])\n",
    "print(target, english_labels[target])\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        batch_size = data.shape[0]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * batch_size\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch + 1, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "    train_loss /= len(test_loader.dataset)\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a test function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            if cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            # sum up batch loss\n",
    "            _, pred = output.data.max(dim=1)\n",
    "            # get the index of the max log-probability\n",
    "            correct += torch.sum(pred == target.data.long()).item()\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        test_accuracy = float(correct) / len(test_loader.dataset)\n",
    "        print('\\nTest set: Average loss: {:.4f},'\n",
    "              ' Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, correct, len(test_loader.dataset),\n",
    "            100. * test_accuracy))\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `find_lr` function provides a learning rate for SGD or Adam, following heuristics from https://arxiv.org/abs/1506.01186:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def loop_loader(data_loader):\n",
    "    while True:\n",
    "        for elem in data_loader:\n",
    "            yield elem\n",
    "\n",
    "def find_lr(model, train_loader, init_lr, max_lr, steps, n_batch_per_step=30):\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=init_lr)\n",
    "    current_lr = init_lr\n",
    "    best_lr = current_lr\n",
    "    best_loss = float('inf')\n",
    "    lr_step = (max_lr - init_lr) / steps\n",
    "\n",
    "    loader = loop_loader(train_loader)\n",
    "    for i in range(steps):\n",
    "        mean_loss = 0\n",
    "        n_seen_samples = 0\n",
    "        for j, (data, target) in enumerate(loader):\n",
    "            if j > n_batch_per_step:\n",
    "                break\n",
    "            optimizer.zero_grad()\n",
    "            if cuda:\n",
    "                data = data.cuda()\n",
    "                target = target.cuda()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            mean_loss += loss.item() * data.shape[0]\n",
    "            n_seen_samples += data.shape[0]\n",
    "            optimizer.step()\n",
    "\n",
    "        mean_loss /= n_seen_samples\n",
    "        print('Step %i, current LR: %f, loss %f' % (i, current_lr, mean_loss))\n",
    "            \n",
    "        if np.isnan(mean_loss) or mean_loss > best_loss * 4:\n",
    "            return best_lr / 4\n",
    "        \n",
    "        if mean_loss < best_loss:\n",
    "            best_loss = mean_loss\n",
    "            best_lr = current_lr\n",
    "\n",
    "        current_lr += lr_step\n",
    "        optimizer.param_groups[0]['lr'] = current_lr\n",
    "\n",
    "    return best_lr / 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load our model on the GPU if required. We then define an optimizer and a learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_interval = 100\n",
    "epochs = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, current LR: 0.000100, loss 2.305745\n",
      "Step 1, current LR: 0.010099, loss 2.204690\n",
      "Step 2, current LR: 0.020098, loss 1.717935\n",
      "Step 3, current LR: 0.030097, loss 1.241666\n",
      "Step 4, current LR: 0.040096, loss 1.051628\n",
      "Step 5, current LR: 0.050095, loss 1.113315\n",
      "Step 6, current LR: 0.060094, loss 1.032816\n",
      "Step 7, current LR: 0.070093, loss 0.993736\n",
      "Step 8, current LR: 0.080092, loss 0.900236\n",
      "Step 9, current LR: 0.090091, loss 0.823854\n",
      "Step 10, current LR: 0.100090, loss 0.791178\n",
      "Step 11, current LR: 0.110089, loss 0.804942\n",
      "Step 12, current LR: 0.120088, loss 0.805085\n",
      "Step 13, current LR: 0.130087, loss 0.767188\n",
      "Step 14, current LR: 0.140086, loss 0.775382\n",
      "Step 15, current LR: 0.150085, loss 0.722176\n",
      "Step 16, current LR: 0.160084, loss 0.750336\n",
      "Step 17, current LR: 0.170083, loss 0.723112\n",
      "Step 18, current LR: 0.180082, loss 0.716810\n",
      "Step 19, current LR: 0.190081, loss 0.730336\n",
      "Step 20, current LR: 0.200080, loss 0.714219\n",
      "Step 21, current LR: 0.210079, loss 0.710831\n",
      "Step 22, current LR: 0.220078, loss 0.676193\n",
      "Step 23, current LR: 0.230077, loss 0.700087\n",
      "Step 24, current LR: 0.240076, loss 0.679877\n",
      "Step 25, current LR: 0.250075, loss 0.711818\n",
      "Step 26, current LR: 0.260074, loss 0.834491\n",
      "Step 27, current LR: 0.270073, loss 0.733919\n",
      "Step 28, current LR: 0.280072, loss 0.797938\n",
      "Step 29, current LR: 0.290071, loss nan\n",
      "Best LR 0.055019500000000034\n"
     ]
    }
   ],
   "source": [
    "if cuda:\n",
    "    model.cuda()\n",
    "\n",
    "model.reset_parameters()\n",
    "lr = find_lr(model, train_loader, 1e-4, 1, 100, 30)\n",
    "model.reset_parameters()\n",
    "\n",
    "print('Best LR', lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,\n",
    "                                                       T_max=3,\n",
    "                                                       last_epoch=-1)\n",
    "\n",
    "logs = {'epoch': [], 'train_loss': [], 'test_loss': [],\n",
    "        'test_accuracy': [], 'lr': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.317842\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.956910\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.661878\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.860765\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.630526\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.645251\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.527925\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.570341\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.273928\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.730778\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.666461\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.204510\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.353345\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.387856\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.607189\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.497567\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.583817\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.681633\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.492811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryanboustany/anaconda3/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4251, Accuracy: 8356/10000 (84%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.440497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryanboustany/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.413194\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.365793\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.750515\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.437627\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.616513\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.401706\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.410583\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.521416\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.546623\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.454001\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.506236\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.406716\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.484448\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.488975\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.381195\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.342087\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.275681\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.473836\n",
      "\n",
      "Test set: Average loss: 0.3419, Accuracy: 8756/10000 (88%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.347533\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.425283\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.284886\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.352535\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.336145\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.259150\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.201819\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.876271\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.493990\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.487599\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.436301\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.370905\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.320611\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.399256\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.299420\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.456719\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.329180\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.287409\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.603061\n",
      "\n",
      "Test set: Average loss: 0.3242, Accuracy: 8806/10000 (88%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.404016\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.521605\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.517780\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.211368\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.546111\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.309331\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.365412\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.259931\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.293962\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.311139\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.373362\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.337585\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.329206\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.320703\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.289671\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.424306\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.307375\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.311755\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.158546\n",
      "\n",
      "Test set: Average loss: 0.3084, Accuracy: 8888/10000 (89%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.233309\n",
      "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.337755\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.328965\n",
      "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.398166\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.408628\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.232024\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.339226\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.295270\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.260581\n",
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.321063\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.145435\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.210864\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.388331\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.240157\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.355916\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.551895\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.487200\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.305225\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.464724\n",
      "\n",
      "Test set: Average loss: 0.3084, Accuracy: 8888/10000 (89%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.127491\n",
      "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.338562\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.250810\n",
      "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.262645\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.401684\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.322044\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.411007\n",
      "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.377883\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.436253\n",
      "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.223513\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.321170\n",
      "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.397999\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.214649\n",
      "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.298094\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.131216\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.207363\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.387153\n",
      "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.445999\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.273415\n",
      "\n",
      "Test set: Average loss: 0.3037, Accuracy: 8904/10000 (89%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.267068\n",
      "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.660344\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.377544\n",
      "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.676879\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.594804\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.241852\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.303721\n",
      "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.260211\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.388995\n",
      "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.177905\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.350551\n",
      "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.101481\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.555292\n",
      "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.296504\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.398578\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.497151\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.271443\n",
      "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.482676\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.344805\n",
      "\n",
      "Test set: Average loss: 0.3049, Accuracy: 8872/10000 (89%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.294164\n",
      "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.172772\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.348448\n",
      "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.398109\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.415045\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.642731\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.381721\n",
      "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.645504\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.193192\n",
      "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.606934\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.122128\n",
      "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.410007\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.322932\n",
      "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.400085\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.345188\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.394167\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.413198\n",
      "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.487483\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.154199\n",
      "\n",
      "Test set: Average loss: 0.2995, Accuracy: 8919/10000 (89%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.387282\n",
      "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.470303\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.468872\n",
      "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.165442\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.183019\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.509090\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.210999\n",
      "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.333612\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.279992\n",
      "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.170348\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.243690\n",
      "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.162801\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.522863\n",
      "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.320328\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.323256\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.161896\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.347317\n",
      "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.376361\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.162001\n",
      "\n",
      "Test set: Average loss: 0.2946, Accuracy: 8941/10000 (89%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.107831\n",
      "Train Epoch: 10 [3200/60000 (5%)]\tLoss: 0.232335\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.317511\n",
      "Train Epoch: 10 [9600/60000 (16%)]\tLoss: 0.361683\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.408008\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.537388\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.290258\n",
      "Train Epoch: 10 [22400/60000 (37%)]\tLoss: 0.303818\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.200508\n",
      "Train Epoch: 10 [28800/60000 (48%)]\tLoss: 0.335709\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.471766\n",
      "Train Epoch: 10 [35200/60000 (59%)]\tLoss: 0.175387\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.261103\n",
      "Train Epoch: 10 [41600/60000 (69%)]\tLoss: 0.617593\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.262278\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.220182\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.499473\n",
      "Train Epoch: 10 [54400/60000 (91%)]\tLoss: 0.231413\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.209339\n",
      "\n",
      "Test set: Average loss: 0.2839, Accuracy: 8964/10000 (90%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.156198\n",
      "Train Epoch: 11 [3200/60000 (5%)]\tLoss: 0.187283\n",
      "Train Epoch: 11 [6400/60000 (11%)]\tLoss: 0.422720\n",
      "Train Epoch: 11 [9600/60000 (16%)]\tLoss: 0.660470\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.311506\n",
      "Train Epoch: 11 [16000/60000 (27%)]\tLoss: 0.152736\n",
      "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 0.172811\n",
      "Train Epoch: 11 [22400/60000 (37%)]\tLoss: 0.354091\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.408370\n",
      "Train Epoch: 11 [28800/60000 (48%)]\tLoss: 0.215368\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.592947\n",
      "Train Epoch: 11 [35200/60000 (59%)]\tLoss: 0.293664\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.287294\n",
      "Train Epoch: 11 [41600/60000 (69%)]\tLoss: 0.231808\n",
      "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 0.290100\n",
      "Train Epoch: 11 [48000/60000 (80%)]\tLoss: 0.598285\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.362886\n",
      "Train Epoch: 11 [54400/60000 (91%)]\tLoss: 0.271582\n",
      "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 0.156076\n",
      "\n",
      "Test set: Average loss: 0.2839, Accuracy: 8964/10000 (90%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.203298\n",
      "Train Epoch: 12 [3200/60000 (5%)]\tLoss: 0.390108\n",
      "Train Epoch: 12 [6400/60000 (11%)]\tLoss: 0.393321\n",
      "Train Epoch: 12 [9600/60000 (16%)]\tLoss: 0.296756\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.194890\n",
      "Train Epoch: 12 [16000/60000 (27%)]\tLoss: 0.466654\n",
      "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 0.288180\n",
      "Train Epoch: 12 [22400/60000 (37%)]\tLoss: 0.158372\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.402461\n",
      "Train Epoch: 12 [28800/60000 (48%)]\tLoss: 0.239231\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.261024\n",
      "Train Epoch: 12 [35200/60000 (59%)]\tLoss: 0.390838\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.209371\n",
      "Train Epoch: 12 [41600/60000 (69%)]\tLoss: 0.383606\n",
      "Train Epoch: 12 [44800/60000 (75%)]\tLoss: 0.468124\n",
      "Train Epoch: 12 [48000/60000 (80%)]\tLoss: 0.189076\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.254124\n",
      "Train Epoch: 12 [54400/60000 (91%)]\tLoss: 0.214674\n",
      "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 0.241653\n",
      "\n",
      "Test set: Average loss: 0.2777, Accuracy: 9005/10000 (90%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    train_loss = train(model, optimizer, train_loader, epoch)\n",
    "    test_loss, test_accuracy = test(model, test_loader)\n",
    "    logs['epoch'].append(epoch)\n",
    "    logs['train_loss'].append(train_loss)\n",
    "    logs['test_loss'].append(test_loss)\n",
    "    logs['test_accuracy'].append(test_accuracy)\n",
    "    logs['lr'].append(optimizer.param_groups[0]['lr'])\n",
    "    scheduler.step(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
